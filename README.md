# Dual-Domain-Diffusion-based-Progressive-Style-Rendering

Deep learning models have achieved unprecedented performance in generating images, particularly in the area of style transfer, which has produced some outstanding works. Although some models are capable of rendering in specific artistic styles, not enough is known about the mechanics of how computers painting images due to the black box problem. In this paper, we proposed a Dual-Domain Diffusion based Progressive Style Rendering (D3PSR) method to render the original image with the style of some famous artworks. By using diffusion model for art style transferring, for the first time, we implemented a step-by-step process to understand the computational mechanisms of art style transfer, in contrast with the Blackbox process of classical style generation AI models. The results showed that the texture style we expected to imitate from the artworks can be gradually generated and deepened with the noises (the approach that diffusion model utilizes to generate images), which is similar to the artist's painting process to some extent. From our study, it is shown that semantic structures (e.g., architecture, trees, clouds, etc.) was nicely preserved in our progressive style rendering process. Furthermore, we found that output images could inherit the emotion response of original artworks. To make our study more solid, we introduced quantitative new measures to help understand the progressive style rendering of AI models.
